/*!
\brief	This example demonstrates how to use OpenGL SC creat a surround view application. The camera calibration method is from: https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html
\file	OpenGLSCSurroundView.cpp
\author	PowerVR by Imagination, Developer Technology Team
\copyright Copyright (c) Imagination Technologies Limited.
*/
#include "PVRShell/PVRShell.h"
#include "PVRCore/cameras/TPSCamera.h"

// For test on safety critical enviornment, change the head and cmake definations
#include "PVRUtils/PVRUtilsGles.h"
// #incude "PVRUtils/PVRUtilsGlsc.h"

using pvr::utils::VertexConfiguration;

const char QuadrantModelFileName[] = "Quadrant.pod";
const char CarModelFileName[] = "TestCar.gltf";
const char SurroundCameraRigFileName[] = "CamRig.gltf";

const char CarVertShaderFileName[] = "CarVertShader.vsh";
const char CarFragShaderFileName[] = "CarFragShader.fsh";
const char SurroundVertShaderFileName[] = "SurroundVertShader.vsh";
const char SurroundFragShaderFileName[] = "SurroundFragShader.fsh";

const char CarBinaryShaderName[] = "CarBinaryShader.bin";
const char SurroundBinaryShaderName[] = "SurroundBinaryShader.bin";

const unsigned int MAX_CAMERA_NUM = 4;

struct Material
{
	glm::vec3 albedo; // std140 offset 0
	float roughness; // std140 packed at the end of RGB (offset: 12 bytes)
};

/// <summary>The four parameters of camera calibration could generated by OpenCV</summary>
/// <summary>The view matrix should match the real world camera's location and rotation.</summary>
struct SurroundCamera
{
	std::string name;

	glm::mat4 view;
	glm::vec3 barrelDistortion;
	glm::vec2 tangentialDistortion;
	glm::vec2 sensorSize;
	glm::vec2 sensorCentre;

	GLuint texture;
};

/// <summary>Loading textures as camera feed</summary>
GLuint loadTextures(pvr::IAssetProvider& assetProvider, const std::string& fileName)
{
	GLuint texture = pvr::utils::textureUpload(assetProvider, fileName.c_str());
	gl::BindTexture(GL_TEXTURE_2D, texture);
	gl::TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
	gl::TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);
	gl::TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
	gl::TexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);
	return texture;
}

class CarPass
{
public:
	/// <summary>initialise the car's program</summary>
	/// <param name="assetProvider">Asset provider for loading assets from disk.</param>
	void init(pvr::IAssetProvider& assetProvider)
	{
		const pvr::utils::VertexBindings_Name vertexBindings[] = { { "POSITION", "inVertex" }, { "NORMAL", "inNormal" } };

		std::vector<const char*> defines;

		program =
			pvr::utils::createShaderProgram(assetProvider, CarVertShaderFileName, CarFragShaderFileName, nullptr, nullptr, 0, defines.data(), static_cast<uint32_t>(defines.size()));

		model = pvr::assets::loadModel(assetProvider, CarModelFileName);
		pvr::utils::appendSingleBuffersFromModel(*model, vbos, ibos);
		vertexConfiguration = createInputAssemblyFromMesh(model->getMesh(0), vertexBindings, ARRAY_SIZE(vertexBindings));

		const glm::vec3 albedos = glm::vec3(.01f, .05f, .2f);
		const float roughness = 0.6f;

		material.albedo = albedos;
		material.roughness = roughness;

		gl::GenBuffers(1, &materialUbo);
		gl::BindBuffer(GL_UNIFORM_BUFFER, materialUbo);
		gl::BufferData(GL_UNIFORM_BUFFER, sizeof(material), &material, GL_DYNAMIC_DRAW);
		gl::BindBuffer(GL_UNIFORM_BUFFER, 0);
	}

	/// <summary>Destructor for the car pass</summary>
	~CarPass()
	{
		gl::DeleteBuffers(static_cast<GLsizei>(vbos.size()), vbos.data());
		gl::DeleteBuffers(static_cast<GLsizei>(ibos.size()), ibos.data());
		gl::DeleteProgram(program);
	}

	/// <summary>Renders the car scene</summary>
	void render()
	{
		debugThrowOnApiError("begin Render car Scene");
		gl::UseProgram(program);
		debugThrowOnApiError("bind car pass program");

		for (uint32_t node = 0; node < model->getNumMeshNodes(); ++node)
		{
			uint32_t meshId = model->getMeshNode(node).getObjectId();
			gl::BindBuffer(GL_ARRAY_BUFFER, vbos[meshId]);
			gl::BindBuffer(GL_ELEMENT_ARRAY_BUFFER, ibos[meshId]);
			gl::BindBufferBase(GL_UNIFORM_BUFFER, 3, materialUbo);

			const pvr::assets::Mesh& mesh = model->getMesh(meshId);
			for (uint32_t i = 0; i < vertexConfiguration.attributes.size(); ++i)
			{
				auto& attrib = vertexConfiguration.attributes[i];
				auto& binding = vertexConfiguration.bindings[0];
				gl::EnableVertexAttribArray(attrib.index);
				gl::VertexAttribPointer(attrib.index, attrib.width, pvr::utils::convertToGles(attrib.format), dataTypeIsNormalised(attrib.format), binding.strideInBytes,
					reinterpret_cast<const void*>(static_cast<uintptr_t>(attrib.offsetInBytes)));
			}
			debugThrowOnApiError("Render Node (before draw)");
			gl::DrawElements(GL_TRIANGLES, mesh.getNumFaces() * 3, pvr::utils::convertToGles(mesh.getFaces().getDataType()), nullptr);

			for (uint32_t i = 0; i < vertexConfiguration.attributes.size(); ++i)
			{
				auto& attrib = vertexConfiguration.attributes[i];
				gl::DisableVertexAttribArray(attrib.index);
			}
			debugThrowOnApiError("Render Node (after draw)");
		}
	}

private:
	pvr::assets::ModelHandle model;
	GLuint program; // Program should be build to binary before running under the safety critical enviornment.
	std::vector<GLuint> vbos;
	std::vector<GLuint> ibos;
	GLuint materialUbo;
	Material material;
	pvr::utils::VertexConfiguration vertexConfiguration;
};

class SurroundPass
{
public:
	/// <summary>initialise the surround's program</summary>
	/// <param name="assetProvider">Asset provider for loading assets from disk.</param>
	void init(pvr::IAssetProvider& assetProvider)
	{
		const pvr::utils::VertexBindings_Name vertexBindings[] = { { "POSITION", "inVertex" }, { "NORMAL", "inColor" }, { "TEXCOORD_0", "inTexCoord" } };

		std::vector<const char*> defines;

		program = pvr::utils::createShaderProgram(
			assetProvider, SurroundVertShaderFileName, SurroundFragShaderFileName, nullptr, nullptr, 0, defines.data(), static_cast<uint32_t>(defines.size()));

		model = pvr::assets::loadModel(assetProvider, QuadrantModelFileName);
		pvr::utils::appendSingleBuffersFromModel(*model, vbos, ibos);
		vertexConfiguration = createInputAssemblyFromMesh(model->getMesh(0), vertexBindings, ARRAY_SIZE(vertexBindings));

		CameraId0 = gl::GetUniformLocation(program, "uCameraID0");
		CameraId1 = gl::GetUniformLocation(program, "uCameraID1");
		CameraTexture0 = gl::GetUniformLocation(program, "sCamera0");
		CameraTexture1 = gl::GetUniformLocation(program, "sCamera1");

		// figure out how to blend two feed in one sector of surround view
		BlendZone = gl::GetUniformLocation(program, "uBlendZone");
		RotationMat = gl::GetUniformLocation(program, "uRotationMat");

		gl::GenSamplers(1, &this->cameraSampler);
		gl::SamplerParameteri(this->cameraSampler, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);
		gl::SamplerParameteri(this->cameraSampler, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
		gl::SamplerParameteri(this->cameraSampler, GL_TEXTURE_WRAP_R, GL_CLAMP_TO_EDGE);
		gl::SamplerParameteri(this->cameraSampler, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
		gl::SamplerParameteri(this->cameraSampler, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);

		this->cameraRig = pvr::assets::loadModel(assetProvider, SurroundCameraRigFileName);
		surroundCameras.resize(MAX_CAMERA_NUM);

		for (uint32_t i = 0; i < this->cameraRig->getNumNodes(); i++)
		{
			const std::string& nodename = this->cameraRig->getNode(i).getName();
			const glm::mat4 xform = this->cameraRig->getWorldMatrix(i);
			uint32_t camid = -1;
			if (nodename == "SurroundFront")
				camid = 0;
			else if (nodename == "SurroundRight")
				camid = 1;
			else if (nodename == "SurroundBack")
				camid = 2;
			else if (nodename == "SurroundLeft")
				camid = 3;
			if (camid != -1)
			{
				this->surroundCameras[camid].view = glm::inverse(xform);

				Log("%d: %s", i, nodename.c_str());
			}
		}

		// Surround Camera UBO
		{
			std::vector<std::string> names = { "Front", "Right", "Back", "Left" };
			for (uint32_t i = 0; i < 4; i++)
			{
				auto& cam = this->surroundCameras[i];
				cam.name = names[i];
				cam.barrelDistortion = glm::vec3(-0.3195085163816964f, 0.08499829326044542f, -0.008842254974808755f);
				cam.tangentialDistortion = glm::vec2(-0.0026617595738698385f, -0.0014907257998599947f);
				cam.sensorCentre = glm::vec2(494.944883277257f, 498.7984019931958f);
				cam.sensorSize = glm::vec2(387.80803649905687f, 387.077024182395f);
				cam.texture = loadTextures(assetProvider, "Car" + names[i] + ".pvr");
			}

			pvr::utils::StructuredMemoryDescription descUbo("CamerasUBO", 1,
				{ { "ViewMatrix", MAX_CAMERA_NUM, pvr::GpuDatatypes::mat4x4 }, { "K", MAX_CAMERA_NUM, pvr::GpuDatatypes::vec3 }, { "P", MAX_CAMERA_NUM, pvr::GpuDatatypes::vec2 },
					{ "sensorSize", MAX_CAMERA_NUM, pvr::GpuDatatypes::vec2 }, { "sensorCentre", MAX_CAMERA_NUM, pvr::GpuDatatypes::vec2 } });

			this->surroundCamerasUboView.init(descUbo);
			gl::GenBuffers(1, &camerasUbo);
			gl::BindBuffer(GL_UNIFORM_BUFFER, camerasUbo);
			gl::BufferData(GL_UNIFORM_BUFFER, static_cast<GLsizeiptr>(surroundCamerasUboView.getSize()), nullptr, GL_STATIC_DRAW);

			gl::BindBufferBase(GL_UNIFORM_BUFFER, 2, camerasUbo);
			void* uboData = gl::MapBufferRange(GL_UNIFORM_BUFFER, 0, static_cast<GLsizeiptr>(surroundCamerasUboView.getSize()), GL_MAP_WRITE_BIT);
			surroundCamerasUboView.pointToMappedMemory(uboData);
			for (size_t i = 0; i < MAX_CAMERA_NUM; i++)
			{
				surroundCamerasUboView.getElement(0, i).setValue(this->surroundCameras[i].view);
				surroundCamerasUboView.getElement(1, i).setValue(this->surroundCameras[i].barrelDistortion);
				surroundCamerasUboView.getElement(2, i).setValue(this->surroundCameras[i].tangentialDistortion);
				surroundCamerasUboView.getElement(3, i).setValue(this->surroundCameras[i].sensorSize);
				surroundCamerasUboView.getElement(4, i).setValue(this->surroundCameras[i].sensorCentre);
			}
			gl::UnmapBuffer(GL_UNIFORM_BUFFER);
		}
	}

	/// <summary>Destructor for the surround pass</summary>
	~SurroundPass()
	{
		gl::DeleteBuffers(static_cast<GLsizei>(vbos.size()), vbos.data());
		gl::DeleteBuffers(static_cast<GLsizei>(ibos.size()), ibos.data());
		gl::DeleteProgram(program);
	}

	/// <summary>Renders the surround scene</summary>
	void render()
	{
		debugThrowOnApiError("begin Render surround Scene");
		gl::UseProgram(program);
		debugThrowOnApiError("bind surround pass program");

		gl::BindBuffer(GL_UNIFORM_BUFFER, this->camerasUbo);
		gl::BindSampler(0, this->cameraSampler);
		gl::BindSampler(1, this->cameraSampler);
		debugThrowOnApiError("BindSampler");

		gl::Uniform1i(CameraTexture0, 0);
		gl::Uniform1i(CameraTexture1, 1);

		float blendPosition = 0.65f;
		const glm::vec2 blendZone = glm::vec2(blendPosition - 0.16f * 0.5f, blendPosition + 0.16f * 0.5f);
		gl::Uniform2fv(BlendZone, 1, glm::value_ptr(blendZone));
		blendPosition = 1.f - blendPosition;

		for (uint32_t q = 0; q < 4; q++)
		{
			const glm::mat4 rotation = glm::rotate(glm::radians(-90.f) * q, glm::vec3(0.f, 1.f, 0.f));

			const uint32_t id0 = q;
			const uint32_t id1 = (id0 + 1) % 4;

			gl::Uniform1i(CameraId0, id0);
			gl::Uniform1i(CameraId1, id1);

			gl::ActiveTexture(GL_TEXTURE0);
			gl::BindTexture(GL_TEXTURE_2D, surroundCameras[id0].texture);
			gl::ActiveTexture(GL_TEXTURE1);
			gl::BindTexture(GL_TEXTURE_2D, surroundCameras[id1].texture);

			debugThrowOnApiError("Active Texture");

			for (uint32_t node = 0; node < model->getNumMeshNodes(); ++node)
			{
				uint32_t meshId = model->getMeshNode(node).getObjectId();
				gl::BindBuffer(GL_ARRAY_BUFFER, vbos[meshId]);
				gl::BindBuffer(GL_ELEMENT_ARRAY_BUFFER, ibos[meshId]);
				gl::BindBufferBase(GL_UNIFORM_BUFFER, 3, materialUbo);

				const pvr::assets::Mesh& mesh = model->getMesh(meshId);
				for (uint32_t i = 0; i < vertexConfiguration.attributes.size(); ++i)
				{
					auto& attrib = vertexConfiguration.attributes[i];
					auto& binding = vertexConfiguration.bindings[0];
					gl::EnableVertexAttribArray(attrib.index);
					gl::VertexAttribPointer(attrib.index, attrib.width, pvr::utils::convertToGles(attrib.format), dataTypeIsNormalised(attrib.format), binding.strideInBytes,
						reinterpret_cast<const void*>(static_cast<uintptr_t>(attrib.offsetInBytes)));
				}
				gl::UniformMatrix4fv(RotationMat, 1, GL_FALSE, glm::value_ptr(rotation));

				debugThrowOnApiError("Render Node (before draw)");
				gl::DrawElements(GL_TRIANGLES, mesh.getNumFaces() * 3, pvr::utils::convertToGles(mesh.getFaces().getDataType()), nullptr);

				for (uint32_t i = 0; i < vertexConfiguration.attributes.size(); ++i)
				{
					auto& attrib = vertexConfiguration.attributes[i];
					gl::DisableVertexAttribArray(attrib.index);
				}
				debugThrowOnApiError("Render Node (after draw)");
			}
		}
		gl::BindSampler(0, 0);
		gl::BindSampler(1, 0);
	}

private:
	pvr::assets::ModelHandle model;
	pvr::assets::ModelHandle cameraRig;

	GLuint program;
	std::vector<GLuint> vbos;
	std::vector<GLuint> ibos;
	GLuint materialUbo;

	pvr::utils::StructuredBufferView surroundCamerasUboView;
	GLuint camerasUbo;
	GLuint cameraSampler;

	GLuint CameraId0;
	GLuint CameraId1;
	GLuint CameraTexture0;
	GLuint CameraTexture1;
	GLuint BlendZone;
	GLuint RotationMat;

	std::vector<SurroundCamera> surroundCameras;

	pvr::utils::VertexConfiguration vertexConfiguration;
};

class OpenGLSCSurroundView : public pvr::Shell
{
	struct DeviceResources
	{
		pvr::EglContext context;

		GLuint uboStatic; // static UBO
		GLuint uboPerFrame; // static UBO
		GLuint uboPerModel;
		GLuint uboSurroundCameras; // surround enviornment UBO (physical cameras)

		CarPass carPass;
		SurroundPass surroundPass;

		DeviceResources() {}
		~DeviceResources()
		{
			// Delete OpenGL object operation will not work under the safety critical environment
			gl::DeleteBuffers(1, &uboStatic);
			gl::DeleteBuffers(1, &uboPerFrame);
			gl::DeleteBuffers(1, &uboPerModel);
		}
	};

	std::unique_ptr<DeviceResources> _deviceResources;
	// model matrix
	pvr::utils::StructuredBufferView _uboPerModelBufferView;
	// ViewProject matrix, camera position
	pvr::utils::StructuredBufferView _uboPerFrameBufferView;
	std::vector<char> _uboDynamicData;
	std::vector<char> _uboMaterialData;
	glm::mat4 _projMtx;

	pvr::TPSOrbitCamera _camera;
	std::vector<SurroundCamera> surroundCameras;

	uint64_t lastTime = 0;
	int flag = 1;

public:
	OpenGLSCSurroundView() {}

	void createProgram();
	virtual pvr::Result initApplication();
	virtual pvr::Result initView();
	virtual pvr::Result releaseView();
	virtual pvr::Result quitApplication();
	virtual pvr::Result renderFrame();
	void createUbo();
	void cameraAnimation();
};

/// <summary>Code in initApplication() will be called by Shell once per run, before the rendering context is created.
/// Used to initialize variables that are not dependent on it (e.g. external modules, loading meshes, etc.). If the rendering
/// context is lost, initApplication() will not be called again.</summary>
pvr::Result OpenGLSCSurroundView::initApplication() { return pvr::Result::Success; }

/// <summary>Code in initView() will be called by Shell upon initialization or after a change in the rendering context.
/// Used to initialize variables that are dependent on the rendering context(e.g.textures, vertex buffers, etc.)</summary>
/// <returns>Result::Success if no error occurred.</returns>
pvr::Result OpenGLSCSurroundView::initView()
{
	_deviceResources = std::make_unique<DeviceResources>();
	_deviceResources->context = pvr::createEglContext();

	// Create the context. Set API to Unspecified if need to test under the safety critical environment
	_deviceResources->context->init(getWindow(), getDisplay(), getDisplayAttributes(), pvr::Api::OpenGLES31);
	// _deviceResources->context->init(getWindow(), getDisplay(), getDisplayAttributes(), pvr::Api::Unspecified);

	_deviceResources->carPass.init(*this);
	_deviceResources->surroundPass.init(*this);

	gl::Viewport(0, 0, getWidth(), getHeight());

	createUbo();

	debugThrowOnApiError("Error generating samplers");

	_projMtx = pvr::math::perspectiveFov(pvr::Api::OpenGLES31, glm::radians(65.f), static_cast<float>(this->getWidth()), static_cast<float>(this->getHeight()), 0.1f, 2000.f);

	_camera.setDistanceFromTarget(10.f);
	_camera.setInclination(0.f);

	gl::DepthMask(GL_TRUE);
	gl::CullFace(GL_BACK);
	gl::FrontFace(GL_CCW);
	gl::Enable(GL_CULL_FACE);
	gl::Enable(GL_DEPTH_TEST);

	return pvr::Result::Success;
}

/// <summary>Code in releaseView() will be called by Shell when the application quits or before a change in the rendering context.</summary>
/// <returns>Result::Success if no error occurred.</returns>
pvr::Result OpenGLSCSurroundView::releaseView()
{
	_deviceResources.reset();
	return pvr::Result::Success;
}

/// <summary>Code in quitApplication() will be called by Shell once per run, just before exiting the program.
/// quitApplication() will not be called every time the rendering context is lost, only before application exit.</summary>
/// <returns>Result::Success if no error occurred.</returns>
pvr::Result OpenGLSCSurroundView::quitApplication() { return pvr::Result::Success; }

pvr::Result OpenGLSCSurroundView::renderFrame()
{
	debugThrowOnApiError("Begin Frame");
	gl::Clear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

	// cameraAnimation();

	gl::BindBuffer(GL_UNIFORM_BUFFER, _deviceResources->uboPerFrame);
	void* mappedMemory = nullptr;
	mappedMemory = gl::MapBufferRange(GL_UNIFORM_BUFFER, 0, (size_t)_uboPerFrameBufferView.getSize(), GL_MAP_WRITE_BIT);
	_uboPerFrameBufferView.pointToMappedMemory(mappedMemory);

	const glm::mat4 viewProj = _projMtx * _camera.getViewMatrix();
	_uboPerFrameBufferView.getElement(0).setValue(viewProj);
	_uboPerFrameBufferView.getElement(1).setValue(_camera.getCameraPosition());

	gl::UnmapBuffer(GL_UNIFORM_BUFFER);

	gl::BindBufferRange(GL_UNIFORM_BUFFER, 0, _deviceResources->uboPerFrame, 0, static_cast<GLsizeiptr>(_uboPerFrameBufferView.getSize()));
	debugThrowOnApiError("ERROR");

	gl::BindBufferRange(GL_UNIFORM_BUFFER, 1, _deviceResources->uboPerModel, 0, static_cast<GLsizeiptr>(_uboPerModelBufferView.getDynamicSliceSize()));
	debugThrowOnApiError("ERROR");

	_deviceResources->carPass.render();
	_deviceResources->surroundPass.render();

	if (this->shouldTakeScreenshot()) { pvr::utils::takeScreenshot(this->getScreenshotFileName(), this->getWidth(), this->getHeight()); }

	_deviceResources->context->swapBuffers();
	return pvr::Result::Success;
}

void OpenGLSCSurroundView::cameraAnimation()
{
	auto currentTime = getTime();
	if ((currentTime - lastTime) > 9000)
	{
		lastTime = currentTime;
		flag = -flag;
	}
	float angle = getFrameTime() * .1f * flag;
	_camera.addInclination((angle < 15.f) ? 15.f : ((angle > 90.f) ? 90.f : angle));
}

/// <summary>Create common uniform buffer for two pass</summary>
void OpenGLSCSurroundView::createUbo()
{
	debugThrowOnApiError("ERROR");
	{
		pvr::utils::StructuredMemoryDescription memDesc;
		memDesc.addElement("ModelMatrix", pvr::GpuDatatypes::mat4x4);
		GLint uniformAlignment = 0;
		gl::GetIntegerv(GL_UNIFORM_BUFFER_OFFSET_ALIGNMENT, &uniformAlignment);
		_uboPerModelBufferView.initDynamic(memDesc, 1, pvr::BufferUsageFlags::UniformBuffer, uniformAlignment);
		std::vector<char> _uboModelData(static_cast<const unsigned int>(_uboPerModelBufferView.getSize()));

		_uboPerModelBufferView.pointToMappedMemory(_uboModelData.data());
		_uboPerModelBufferView.getElement(0, 0, 0).setValue(glm::identity<glm::mat4x4>());

		gl::GenBuffers(1, &_deviceResources->uboPerModel);
		gl::BindBuffer(GL_UNIFORM_BUFFER, _deviceResources->uboPerModel);

		gl::BufferData(GL_UNIFORM_BUFFER, static_cast<GLsizeiptr>(_uboPerModelBufferView.getSize()), _uboModelData.data(), GL_STATIC_DRAW);
	}

	debugThrowOnApiError("ERROR");
	{
		pvr::utils::StructuredMemoryDescription memDesc;
		memDesc.addElement("VPMatrix", pvr::GpuDatatypes::mat4x4);
		memDesc.addElement("camPos", pvr::GpuDatatypes::vec3);
		_uboPerFrameBufferView.init(memDesc);
		_uboDynamicData.resize(static_cast<const unsigned int>(_uboPerFrameBufferView.getSize()));
		gl::GenBuffers(1, &_deviceResources->uboPerFrame);
		gl::BindBuffer(GL_UNIFORM_BUFFER, _deviceResources->uboPerFrame);
		gl::BufferData(GL_UNIFORM_BUFFER, static_cast<GLsizeiptr>(_uboPerFrameBufferView.getSize()), nullptr, GL_DYNAMIC_DRAW);
	}
	debugThrowOnApiError("ERROR");
}

/// <summary>This function must be implemented by the user of the shell. The user should return its pvr::Shell object defining the behaviour of the application.</summary>
/// <returns>Return a unique ptr to the demo supplied by the user.</returns>
std::unique_ptr<pvr::Shell> pvr::newDemo() { return std::make_unique<OpenGLSCSurroundView>(); }